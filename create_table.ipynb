{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(\"timelogger.db\") as con:\n",
    "    cursor = con.cursor()\n",
    "    now = datetime.datetime.now()\n",
    "    now = now - datetime.timedelta(days=1)\n",
    "    t = cursor.execute(\"\"\"INSERT INTO timelog (id, start_timestamp, end_timestamp)\n",
    "                    VALUES (?, ?, ?)\"\"\",\n",
    "                    (1000001, now.timestamp(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 1720382372.06768, end = 1720382384.551723\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(\"timelogger.db\") as con:\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(\"\"\"select * from timelog \"\"\")\n",
    "    for log in cursor.fetchall():\n",
    "        print(f\"start = {log[1]}, end = {log[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 7, 7, 0, 0, 0, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(1720299600) + datetime.timedelta(microseconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(\"timelogger.db\") as con:\n",
    "    data = pd.read_sql_query(\"SELECT * FROM timelog\", con, index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(data.iloc[0][\"end_timestamp\"]).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day(timestamp):\n",
    "    date = datetime.datetime.fromtimestamp(timestamp)\n",
    "    delta = datetime.timedelta(days=0, hours=date.hour, minutes=date.minute, seconds=date.second, microseconds=date.microsecond)\n",
    "    return date - delta\n",
    "\n",
    "def get_month(timestamp):\n",
    "    date = datetime.datetime.fromtimestamp(timestamp)\n",
    "    res = datetime.datetime(year=date.year, month=date.month)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>1 days 01:44:10.580604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        work_time\n",
       "month                            \n",
       "2024-06-30 1 days 01:44:10.580604"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"work_time\"] = np.array(list(map(datetime.datetime.fromtimestamp ,data[\"end_timestamp\"]))) -\\\n",
    "                    np.array(list(map(datetime.datetime.fromtimestamp ,data[\"start_timestamp\"] )))\n",
    "data[\"day\"] = np.array(list(map(get_day ,data[\"start_timestamp\"] )))\n",
    "data[\"month\"] = np.array(list(map(get_month ,data[\"start_timestamp\"] )))\n",
    "data[[\"month\", \"work_time\"]].groupby(\"month\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | list[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcoerce_float\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[str] | dict[str, str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[str] | dict[str, str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeArg | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeBackend | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame | Iterator[DataFrame]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Read SQL query into a DataFrame.\n",
      "\n",
      "Returns a DataFrame corresponding to the result set of the query\n",
      "string. Optionally provide an `index_col` parameter to use one of the\n",
      "columns as the index, otherwise default integer index will be used.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "sql : str SQL query or SQLAlchemy Selectable (select or text object)\n",
      "    SQL query to be executed.\n",
      "con : SQLAlchemy connectable, str, or sqlite3 connection\n",
      "    Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "    library. If a DBAPI2 object, only sqlite3 is supported.\n",
      "index_col : str or list of str, optional, default: None\n",
      "    Column(s) to set as index(MultiIndex).\n",
      "coerce_float : bool, default True\n",
      "    Attempts to convert values of non-string, non-numeric objects (like\n",
      "    decimal.Decimal) to floating point. Useful for SQL result sets.\n",
      "params : list, tuple or dict, optional, default: None\n",
      "    List of parameters to pass to execute method.  The syntax used\n",
      "    to pass parameters is database driver dependent. Check your\n",
      "    database driver documentation for which of the five syntax styles,\n",
      "    described in PEP 249's paramstyle, is supported.\n",
      "    Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}.\n",
      "parse_dates : list or dict, default: None\n",
      "    - List of column names to parse as dates.\n",
      "    - Dict of ``{column_name: format string}`` where format string is\n",
      "      strftime compatible in case of parsing string times, or is one of\n",
      "      (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds\n",
      "      to the keyword arguments of :func:`pandas.to_datetime`\n",
      "      Especially useful with databases without native Datetime support,\n",
      "      such as SQLite.\n",
      "chunksize : int, default None\n",
      "    If specified, return an iterator where `chunksize` is the number of\n",
      "    rows to include in each chunk.\n",
      "dtype : Type name or dict of columns\n",
      "    Data type for data or columns. E.g. np.float64 or\n",
      "    {‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’}.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "dtype_backend : {\"numpy_nullable\", \"pyarrow\"}, defaults to NumPy backed DataFrames\n",
      "    Which dtype_backend to use, e.g. whether a DataFrame should have NumPy\n",
      "    arrays, nullable dtypes are used for all dtypes that have a nullable\n",
      "    implementation when \"numpy_nullable\" is set, pyarrow is used for all\n",
      "    dtypes if \"pyarrow\" is set.\n",
      "\n",
      "    The dtype_backends are still experimential.\n",
      "\n",
      "    .. versionadded:: 2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or Iterator[DataFrame]\n",
      "\n",
      "See Also\n",
      "--------\n",
      "read_sql_table : Read SQL database table into a DataFrame.\n",
      "read_sql : Read SQL query or database table into a DataFrame.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Any datetime values with time zone information parsed via the `parse_dates`\n",
      "parameter will be converted to UTC.\n",
      "\u001b[0;31mFile:\u001b[0m      /opt/miniconda3/envs/autobid/lib/python3.9/site-packages/pandas/io/sql.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?pd.read_sql_query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
